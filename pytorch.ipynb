{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch tutorial\n",
    "Based on the book [Deep Learning with Pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf), this is mostly focused on the PyTorch API and Part I of the book and not so much on giving an intro to deep learning. Refer to the book and its corresponding [code on Github](https://github.com/deep-learning-with-pytorch/dlwpt-code/tree/master/) for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "PyTorch is a library for Python programs that facilitates building deep learning projects. It emphasizes flexibility and allows deep learning models to be expressed in idiomatic Python. PyTorch operates in eager mode by default. That is, whenever an instruction involing PyTorch is executed by the Python interpreter, the corresponding operation is immediately carried out by the underlying C++ or CUDA implementation. PyTorch also provides a way to compile models of ahead of time through TorchScipt. Using TorchScript, PyTorch can serialize a model into a set of instructions that can be invoked independently from Python, such as with ONNX. This is similar to how Tensorflow 1.0 was built in that the user had to define a computational graph that they later executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We need to convert each sample from our data into something PyTorch can actually handle: tensors or multidimensional arrays. In the context of deep learning, tensors refer to the generalization of vectors and matrices to an arbitrary number of dimensions. They are similar to Numpy arrays and can be indexed in the same way but offer the ability to perform computation on GPUs. All items in a tensor must be numbers of the same type; supported types are defined in [torch.dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype) with the default being `torch.float32`. Both Numpy arrays and PyTorch tensors are allocated as contiguous blocks of memory containing C numeric types as opposed to Python lists which are collections of Python objects individually allocated throughout memory (see figure 3.3 in the book). Memory footprint is managed by `torch.Storage` instances storing tensors in memory as 1d contiguous blocks, improving data locality and performance. \n",
    "\n",
    "`torch.save` and `torch.load` operate using the pickle protocol and can be used to save and load tensors. For interoperability, hdf5 is also supported.\n",
    "\n",
    "Images are usually stored in a volume (num images x num rows x num cols). Similarly, time series data are stored in a volume where one dimension corresponds a unit of time the data is stored in (t x num rows x num cols).\n",
    "\n",
    "Neural networks take tensors as input and produce tensors as outputs. In\n",
    "fact, all operations within a neural network and during optimization are operations\n",
    "between tensors, and all parameters (for example, weights and biases) in a neural\n",
    "network are tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3, 3, dtype=torch.int)\n",
    "b = torch.ones(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've constructed two 3x3 tensors of 1s and when added we should get a 3x3 tensor of 2s. Slicing and reshaping tensors can be done with `torch.view`. This avoids copying such that the view shares the same underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.view(-1, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add an extra dimension to a tensor using the `None` indexing or the `unsqueeze` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor API has many operations in the `torch` [module](https://pytorch.org/docs/stable/torch.html) but can also be called as methods of a tensor object. For example, with `unsqueeze` above we called it as a method of tensor `a` but we can also call it through the `torch` module. There are a number of operations though that exist only as methods of the tensor object and they operate inplace; they're identified by a trailing underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, our tensors are stored on the CPU. We can also transfer or create them on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both `b` and `points_gpu` are in GPU RAM and we can start seeing performance optimizations with operations on the GPU. We can also go back and forth between Pytorch and Numpy. If we were to convert a PyTorch tensor stored on the GPU to numpy, it would make a copy over to CPU, however converting a tensor on CPU RAM to numpy comes at no cost since they both use the same underlying buffer for storage. It's good to note that numpy arrays are stored as `torch.float64` when converted so it's usually best to convert to `torch.float32` to avoid memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.random.randn(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_from_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4850, -0.8921],\n",
       "        [-0.4044, -0.0816]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_from_np.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.48500536, -0.89214756],\n",
       "       [-0.40442433, -0.08158075]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_from_np.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also name each dimension within tensors so that that they are easier to keep track. For example if we have 2 4x4 images with 3 channels: RGB. Funtions accepting dimension arguments can now take names instead. It's still an experimental feature so we won't go too in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/pytorch_37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1609143291274/work/c10/core/TensorImpl.h:890.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.randn(2, 3, 4, 4, names=[\"batch\", \"channels\", \"rows\", \"columns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4, 4]), ('batch', 'channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape, imgs.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6343,  1.5833, -0.0329,  0.1315],\n",
       "         [-1.7858,  1.7780, -0.3074, -0.9811],\n",
       "         [ 0.0191, -1.0221, -1.0766,  1.0057],\n",
       "         [ 2.2630,  0.5581, -0.8069,  1.1776]],\n",
       "\n",
       "        [[ 0.4011,  0.6641,  1.8183,  0.6076],\n",
       "         [ 1.2858,  2.3704, -0.4399,  1.4958],\n",
       "         [ 0.2001,  1.7927,  2.6371,  2.9855],\n",
       "         [-2.7196,  0.7211,  0.2021, -0.4641]],\n",
       "\n",
       "        [[ 0.6448,  0.2991, -1.6020,  1.5254],\n",
       "         [-0.1349,  0.6821,  0.4125, -2.0789],\n",
       "         [-0.5938,  0.6197, -0.8342, -0.6182],\n",
       "         [-1.7776, -0.5511, -1.2878,  0.1249]]],\n",
       "       names=('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.sum(\"batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bridge between our custom data (in whatever format it might be) and a standardized PyTorch tensor is the `Dataset` class PyTorch provides in `torch.utils.data`. Simply put, it's object that is required to implement two methods: `__len__` and `__getitem__`. The former should return the number of items in the dataset; the latter should return the item, consisting of a sample and its corresponding label (an integer index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10 = datasets.CIFAR10(\".\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F465D7E0ED0>, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar10[3]\n",
    "img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader` is another class provided under `torch.utils.data` that helps with shuffling and organizing data into minibatches.\n",
    "* lets us sample data with various sampling strategies. \n",
    "* implements `__next__` so it can be iterated over and integrated directly in our training loop\n",
    "* provides functionality to load data in parallel by spawning child processes in the background so that it’s ready and waiting for the training loop as soon as the loop can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f465d7ea090>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll take some input temperature data in celcius `t_c` and some output data in unknown units `t_u`. We'll assume there exists a linear relationship between the input and output and we'd like to learn their relationship by estimating paremeters of a linear model. That is we assume we can multiply `t_u` by some amount `w` and add a constant `b` to get `t_c`: `t_c = w*t_u + b`. We'll estimate parameters `w` (weights) and `b` (biases) since they are not known. If we choose some values for `w` and `b`, how do we know how good of an estimate they are? We'll use a loss function to measure the error between our predictions `t_p` and desired outputs `t_c`: `(t_p - t_c)^2` (see section 5.3 for why we use this loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.1664, 17.0082, 17.6733, 24.5272, 17.1238, 14.9838, 10.6459,  7.1467,\n",
       "        14.8392, 18.3095, 20.6231])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the parameters and invoke the model\n",
    "w = torch.randn(())\n",
    "b = torch.randn(())\n",
    "t_p = model(t_u, w, b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t_p, t_c):\n",
    "    \"\"\"Loss function: mean squared error\"\"\"\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.0433)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the loss function\n",
    "mse(t_p, t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep randomly choosing values of `w` and `b` until we find values where the loss function is small enough but that's inefficient. Instead we'll use an iterative procedure to update our parameters called gradient descent. We'll look at a small neighborhood around the current value of each parameter and find the direction where the loss is decreasing the most using the derivative. In a model with two or more parameters like the one we’re dealing with, we compute the individual derivatives of the loss with respect to each parameter and put them in a vector of derivatives: the gradient `[dloss/dw, dloss/db]`. In order to compute this vector of derivatives we'll use the chain rule to compute `dloss/dw = dloss/dmodel * dmodel/dw` and `dloss/db = dloss/dmodel * dmodel/db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_dmodel(t_p, t_c):\n",
    "    \"\"\"Derivative of loss function (t_p - t_c)^2\n",
    "    with respect to the output of the model t_p\"\"\"\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)\n",
    "    return dsq_diffs\n",
    "\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    \"\"\"Derivate of the model w * t_u + b\n",
    "    with respect to w\"\"\"\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    \"\"\"Derivate of the model w * t_u + b\n",
    "    with respect to b\"\"\"\n",
    "    return 1.0\n",
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_dmodel(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])\n",
    "\n",
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    \"\"\"Typically the training loop is implemented as a standard Python for loop. \n",
    "    Pytorch lightning gives more high level API on top of pytorch for training\n",
    "    \n",
    "    n_epochs: number of epochs - a training iteration that results in updating parameters for all training samples\n",
    "    learning_rate: scaling factor that determines how much we update our weights by\n",
    "    \"\"\"\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        \n",
    "        # forward pass\n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = mse(t_p, t_c)\n",
    "        # backward pass - backpropagating derivatives\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        # update parameters\n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss))) # <3>\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss 22.148710\n",
      "Epoch 200, Loss 16.608067\n",
      "Epoch 300, Loss 12.664559\n",
      "Epoch 400, Loss 9.857804\n",
      "Epoch 500, Loss 7.860115\n",
      "Epoch 600, Loss 6.438284\n",
      "Epoch 700, Loss 5.426309\n",
      "Epoch 800, Loss 4.706046\n",
      "Epoch 900, Loss 4.193405\n",
      "Epoch 1000, Loss 3.828538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.8021), tensor(-14.1031))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple normalization to prevent bias and weights from receiving different relative updates\n",
    "t_un = 0.1*t_u\n",
    "w_star, b_star = training_loop(n_epochs = 1000, learning_rate = 1e-2, \n",
    "                               params = torch.tensor([1.0, 0.0]),\n",
    "                               t_u = t_un,  \n",
    "                               t_c = t_c)\n",
    "w_star, b_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f465203bf90>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_p = model(t_un, w_star, b_star)  # <1>\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.xlabel(\"Temperature (°Unknown)\")\n",
    "plt.ylabel(\"Temperature (°Celsius)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy()) # <2>\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have a simple model where it's easy to write out the derivatives for the loss function and each parameter. However, as model complexity grows, this becomes unwieldy. The good news is PyTorch tensors can remember where they come from and can automatically provide the chain of derivatives from parent operations with respect to their inputs. PyTorch creates an autograd graph of operations that is traversed forward for the forward pass and backwards for the backwards pass to compute the gradients. We can re-write our learning procedure above by taking advantage of this autograd functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad=True tells PyTorch to track the entire family tree of tensors resulting from operations on params\n",
    "# the value of the derivative will be automatically populated as a grad attribute of the params tensor\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate the gradient, we start with a tensor with `requires_grad` set to `True`, get the model, compute the loss, then call `backward` on the loss tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(model(t_u, *params), t_c)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1763.8848, grad_fn=<MeanBackward0>), tensor([4517.2969,   82.6000]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `grad` attribute of `params` contains the derivatives of the loss with\n",
    "respect to each element of `params`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that calling `backward` causes gradients to accumulate at leaf nodes. In order to update parameters at each iteration of a training loop, they need to be zerod out explicitly after issuing updates. We can do this easily using the in-place `zero_` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = model(t_u, *params) \n",
    "        loss = mse(t_p, t_c)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the use of `torch.no_grad`. This code block tells PyTorch to update params inplace and not add an edge to the autograd graph. If we were using validation data to track training, computing the loss of the validation data would go in here as well since we wouldn't want to build a graph for that. When using autograd we usually avoid inplace operations as done above because we might need the values we'd modify during the backward pass. Related functionality that can control whether we use autograd or not is `torch.set_grad_enabled(bool)` and is useful to distinguish between training and inference loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss 22.148710\n",
      "Epoch 200, Loss 16.608067\n",
      "Epoch 300, Loss 12.664559\n",
      "Epoch 400, Loss 9.857802\n",
      "Epoch 500, Loss 7.860115\n",
      "Epoch 600, Loss 6.438284\n",
      "Epoch 700, Loss 5.426309\n",
      "Epoch 800, Loss 4.706046\n",
      "Epoch 900, Loss 4.193405\n",
      "Epoch 1000, Loss 3.828538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.8021, grad_fn=<UnbindBackward>),\n",
       " tensor(-14.1031, grad_fn=<UnbindBackward>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_star, b_star = training_loop(n_epochs = 1000, learning_rate = 1e-2, \n",
    "                               params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "                               t_u = t_un,  \n",
    "                               t_c = t_c)\n",
    "w_star, b_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives same result as before when we manually differentiated everything!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we used vanilla gradient descent, but in practice there are better optimization techniques to deal with more complex models. A list of supported optimization algorithms are listed in [torch.optim](https://pytorch.org/docs/stable/optim.html). Every optimizer constructor takes a list of parameters (aka PyTorch tensors, typically with `requires_grad` set to `True`) as the first input. All parameters passed to the optimizer are retained inside the optimizer object so the optimizer can update their values and access their `grad` attribute. Each optimizer exposes two methods: `zero_grad` and `step`. `zero_grad` zeroes the grad attribute of all the parameters passed to the optimizer upon construction. `step` updates the value of those parameters. We'll use the optimizer package below to update our parameters automatically according to the chosen optimizer and a pre-defined learning rate. We can choose a more sophisticated optimizer with an adaptive learning rate such as Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = mse(t_p, t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss 18.730587\n",
      "Epoch 200, Loss 8.292550\n",
      "Epoch 300, Loss 4.275753\n",
      "Epoch 400, Loss 3.178962\n",
      "Epoch 500, Loss 2.962302\n",
      "Epoch 600, Loss 2.931170\n",
      "Epoch 700, Loss 2.927909\n",
      "Epoch 800, Loss 2.927659\n",
      "Epoch 900, Loss 2.927646\n",
      "Epoch 1000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3676, -17.3044], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 1000, \n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above parameters look an awful lot like those necessary for converting Celsius to Fahrenheit so we can conclude that the unknown unit of temperature is probably Fahrenheit. The exact values would be `w=5.5556` and `b=-17.7778`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch.nn\n",
    "`torch.nn` provides common neural network layers and other architectural components such as activation and loss functions. Neural network layers are called `modules` in PyTorch. A PyTorch module is a Python class deriving from the `nn.Module` base class. A module can have one or more `Parameter` instances as attributes, which are tensors whose values are optimized during the training process (think `w` and `b` in our linear model).\n",
    "\n",
    "We'll start by re-writing our linear model with `torch.nn` and then converting it to a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 80% training set and 20% validation set\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_c.unsqueeze_(1)\n",
    "t_u.unsqueeze_(1)\n",
    "\n",
    "t_u_train = t_u[train_indices]\n",
    "t_c_train = t_c[train_indices]\n",
    "\n",
    "t_u_val = t_u[val_indices]\n",
    "t_c_val = t_c[val_indices]\n",
    "\n",
    "t_un_train = 0.1 * t_u_train\n",
    "t_un_val = 0.1 * t_u_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch expects the 0th dimension in the tensor to be the number of examples in the batch, hence the `unsqueeze` op above; the size shows 2 examples, each having one input feature. PyTorch enforces batching because it improves performance if we send just enough compute to saturate the computational power of the GPU. It also helps with some models that calculate statistics over its input data - with a larger batch size, the statistics tend to become more meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling an instance of `nn.Module` with a set of arguments ends up calling a method named `forward` within its `__call__` function. The `forward` method is what executes the forward computation, while `__call__` does other rather important chores before and after calling `forward`. So, it is technically possible to call forward directly, and it will produce the same output as `__call__`, but this should not be done from user code. Now we'll no longer need to initialize parameters `w` and `b` as we do above nor will we need our `model` and `mse` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments are number of input features, number of output features, and whether to include a bias (default True)\n",
    "linear_model = nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8970],\n",
       "        [1.8425]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "linear_model(t_un_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.4681]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.7741], requires_grad=True))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear model contains parameters w and b by default\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=1e-1)\n",
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            t_p_val = model(t_u_val)\n",
    "            loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training loss 22.8464, Validation loss 25.7585\n",
      "Epoch 200, Training loss 12.8624, Validation loss 15.5194\n",
      "Epoch 300, Training loss 7.0491, Validation loss 8.7951\n",
      "Epoch 400, Training loss 4.4477, Validation loss 5.1896\n",
      "Epoch 500, Training loss 3.5104, Validation loss 3.4544\n",
      "Epoch 600, Training loss 3.2351, Validation loss 2.6654\n",
      "Epoch 700, Training loss 3.1687, Validation loss 2.3178\n",
      "Epoch 800, Training loss 3.1557, Validation loss 2.1700\n",
      "Epoch 900, Training loss 3.1535, Validation loss 2.1106\n",
      "Epoch 1000, Training loss 3.1533, Validation loss 2.0885\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 1000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = nn.MSELoss(), # using built in loss\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[5.2572]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-16.7094], requires_grad=True))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are different than the previous training loop since we are now splitting our data\n",
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll replace our linear model with a simple neural network containing a linear module, followed by an activation function, feeding into another linear module (input layer, hidden layer, output layer). The activation functions allow us to learn non-linear relationships between parameters which seems overkill for our problem that was solved using a linear model but it makes it easy to introduce PyTorch concepts. In general, non-linearities allow the output function to have different slopes at different values and values to be concentrated in a certain range which are properties desirable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (activation): Tanh()\n",
       "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(OrderedDict([\n",
    "        (\"hidden\", nn.Linear(1, 8)),\n",
    "        (\"activation\", nn.Tanh()),\n",
    "        (\"output\", nn.Linear(8, 1))\n",
    "    ])\n",
    ")\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` gives a simple way to concatenate modules. We can specify the modules without the named `OrderedDict` as well but this makes it easier to track later on. We choose dimension 8 for the hidden layer arbitrarily - the dimension of the output layer however, must match so we can matrix multiply `1 x 8 x 8 x 1 -> 1 x 1`. We can inspect our model and look at all of its parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden.weight 8 torch.Size([8, 1])\n",
      "hidden.bias 8 torch.Size([8])\n",
      "output.weight 8 torch.Size([1, 8])\n",
      "output.bias 1 torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.numel(), param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0730,  0.1601,  0.0291, -0.1636,  0.2347,  0.3223, -0.1034,  0.2086]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect output layer's initialized weights\n",
    "seq_model.output.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training loss 85.7229, Validation loss 35.9689\n",
      "Epoch 200, Training loss 37.0779, Validation loss 8.4389\n",
      "Epoch 300, Training loss 21.5115, Validation loss 2.4983\n",
      "Epoch 400, Training loss 12.5073, Validation loss 2.2060\n",
      "Epoch 500, Training loss 7.5120, Validation loss 2.5850\n",
      "Epoch 600, Training loss 4.2222, Validation loss 6.9852\n",
      "Epoch 700, Training loss 2.6850, Validation loss 8.0673\n",
      "Epoch 800, Training loss 1.9347, Validation loss 8.3633\n",
      "Epoch 900, Training loss 1.5238, Validation loss 8.4401\n",
      "Epoch 1000, Training loss 1.2923, Validation loss 8.4277\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 1000, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f465176a450>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_range = torch.arange(20., 90.).unsqueeze(1)\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.xlabel(\"Fahrenheit\")\n",
    "plt.ylabel(\"Celsius\")\n",
    "# blue circles are the unknown temperature (well we sort of know it's fahrenheit)\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
    "# do a forward pass of all temps 20-90 degrees, normalize by multiplying by 0.1 as we did during training\n",
    "plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n",
    "# do a forward pass for inference and mark predicted points with an x\n",
    "plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the linear model, the neural network overfits a bit with the s shaped curve above but it's not too bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to build models that do more complex things than just applying one layer after another, we need to leave `nn.Sequential` for something that gives us added flexibility. PyTorch allows us to use any computation in our model by subclassing `nn.Module`. In order to subclass `nn.Module`, at a minimum we need to define a forward function\n",
    "that takes the inputs to the module and returns the output (PyTorch automatically takes care of the backward pass with autograd).  Typically, our computation will use other modules—premade like convolutions or customized. Submodules must be top level attributes so that PyTorch can register them. We typically define submodules in the `__init__` and assign them to `self` for use in the forward function. If a collection is needed we can use `nn.ModuleList` or `nn.ModuleDict`. Let's convert the `nn.Sequential` model we defined to a subclass of `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubclassFunctionalModel(nn.Module):\n",
    "    def __init__(self, n_hidden=8):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.hidden = nn.Linear(1, n_hidden)\n",
    "        self.output = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        hidden_t = self.hidden(input_)\n",
    "        activated_t = torch.tanh(hidden_t)\n",
    "        output_t = self.output(activated_t)\n",
    "        \n",
    "        return output_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we also make use of PyTorch's functional API available in `torch.nn.functional`. We can replace all submodules that don't have any parameters in favor of their functional counterparts. In this case we keep `nn.Linear` in as modules so that `SubclassFunctionalModel` will be able to manage their parameters during training. Since the `torch.tanh` activation function doesn't have any paremeters, we can just use it directly through the functional API instead of having to intialize it first. We can now move our data and model to the GPU and train it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # same training loop as above, just moving data to GPU\n",
    "        t_u_train = t_u_train.to(device=device)\n",
    "        t_u_val = t_u_val.to(device=device)\n",
    "        t_c_train = t_c_train.to(device=device)\n",
    "        t_c_val = t_c_val.to(device=device)\n",
    "        \n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            t_p_val = model(t_u_val)\n",
    "            loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SubclassFunctionalModel().to(device=device)\n",
    "# it is good practice to create the Optimizer after moving the parameters to the appropriate device\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training loss 73.5727, Validation loss 29.7260\n",
      "Epoch 200, Training loss 32.9347, Validation loss 5.9493\n",
      "Epoch 300, Training loss 18.4127, Validation loss 2.8130\n",
      "Epoch 400, Training loss 10.5109, Validation loss 2.7348\n",
      "Epoch 500, Training loss 5.7748, Validation loss 5.7041\n",
      "Epoch 600, Training loss 3.4524, Validation loss 6.7101\n",
      "Epoch 700, Training loss 2.2990, Validation loss 7.6650\n",
      "Epoch 800, Training loss 1.7077, Validation loss 8.2975\n",
      "Epoch 900, Training loss 1.3894, Validation loss 8.3534\n",
      "Epoch 1000, Training loss 1.2029, Validation loss 8.1462\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 1000, \n",
    "    optimizer = optimizer,\n",
    "    model = net,\n",
    "    loss_fn = nn.MSELoss(), # using built in loss\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.distributed` and `torch.nn.parallel` offers functionality for distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `torchvision.models` and Torch Hub provides pretrained models that anyone can use. Although torchvision is a library, Torch Hub is a repository for third party models that allows the community to share models they've built. User just have to include a `hubconf.py` in their repo and Torch Hub will see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet', 'DenseNet', 'GoogLeNet', 'GoogLeNetOutputs', 'Inception3']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
